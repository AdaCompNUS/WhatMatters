{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is notebook to know what is the outcome of each file, what is the distribution of each running Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSOLUTE_DIR = '/home/phong/driving_data/original_gamma/'\n",
    "#ABSOLUTE_DIR = '/home/phong/driving_data/original_gamma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_CODE = {\n",
    "    'GOAL': 0,\n",
    "    'COLLISION': 1,\n",
    "    'LARGE_VEL': 2,\n",
    "    'PATH_OFFSET': 3,\n",
    "    'EGO_KILLED': 4,\n",
    "    'EPS_LIMIT': 5,\n",
    "    'PROCESS_KILL': 6,\n",
    "    'BELIEF_NORM_0': 7,\n",
    "    'INTENTION_ID': 8,\n",
    "    'EGO_LESS_THAN_AGENT': 9,\n",
    "    'STOP_SUDDENLY': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_file_and_return_outcomes(file_name):\n",
    "    eps_len = 120 # 120 seconds for time_scale = 1. \n",
    "    time_scale = None\n",
    "    first_time_ego = None\n",
    "    last_time_ego = None\n",
    "    first_time_agent = None\n",
    "    last_time_agent = None\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if \"time_scale=\" in line:\n",
    "                time_scale = float(line.split('e=')[1])\n",
    "                eps_len = int(120 / time_scale) # This is the maximum time a episode can run\n",
    "\n",
    "            if \"get car state at\" in line:\n",
    "                current_time = float(line.split(\"t=\")[1])\n",
    "                if not first_time_ego:\n",
    "                    first_time_ego = current_time\n",
    "                last_time_ego = current_time\n",
    "\n",
    "            if \"agents at time\" in line:\n",
    "                current_time = float(line.split(\",\")[0].split(\" \")[-1])\n",
    "                if not first_time_agent:\n",
    "                    first_time_agent = current_time\n",
    "                last_time_agent = current_time\n",
    "                \n",
    "            if 'Unusual car vel (too large)' in line:\n",
    "                #print(\"file {} has large vel\".format(file_name))\n",
    "                return ERROR_CODE['LARGE_VEL']\n",
    "            if \"goal reached\" in line:\n",
    "                return ERROR_CODE['GOAL']\n",
    "            if \"collision = 1\" in line:\n",
    "                return ERROR_CODE['COLLISION']\n",
    "            if \"After reaching goal: real_spead is already zero\" in line:\n",
    "                return ERROR_CODE['GOAL']\n",
    "            if \"Path offset too high !!! Node shutting down\" in line:\n",
    "                return ERROR_CODE['PATH_OFFSET']\n",
    "            if \"Ego vehicle killed in ego_vehicle.py\" in line:\n",
    "                return ERROR_CODE['EGO_KILLED']\n",
    "            if \"total_prob == 0\" in line:\n",
    "                return ERROR_CODE['BELIEF_NORM_0']\n",
    "            if \"ERROR: Intention ID\" in line:\n",
    "                return ERROR_CODE['INTENTION_ID']\n",
    "            \n",
    "    # If error, both ego and agent time should be small\n",
    "    if (first_time_agent == None and first_time_ego == None) or \\\n",
    "        ((last_time_ego - first_time_ego < 0.15*eps_len) and (last_time_agent - first_time_agent < 0.15*eps_len)):\n",
    "        return ERROR_CODE['PROCESS_KILL']\n",
    "    \n",
    "    # If episode exceeds limits, both ego and agent time should be exceed\n",
    "    if (last_time_ego - first_time_ego > 0.95*eps_len) and (last_time_agent - first_time_agent > 0.95*eps_len):\n",
    "        return ERROR_CODE['EPS_LIMIT']\n",
    "    \n",
    "    # The left case would be go < 0.95 but agent > 0.95. THis is error because no callback from ego vehicle\n",
    "    if (last_time_ego - first_time_ego < 0.95*eps_len) and (last_time_agent - first_time_agent > 0.95*eps_len):\n",
    "        return ERROR_CODE['EGO_LESS_THAN_AGENT']\n",
    "    # Assertion here because the error\n",
    "    \n",
    "    return ERROR_CODE['STOP_SUDDENLY']\n",
    "\n",
    "    assert False, f\"File {file_name} does not have desired outcome {last_time_ego - first_time_ego} {last_time_agent - first_time_agent}\"\n",
    "\n",
    "def get_outcomes_from_dir(dir_name):\n",
    "    outcomes = [0 for _ in range(len(ERROR_CODE))]\n",
    "\n",
    "    for root, subdirs, files in os.walk(ABSOLUTE_DIR):\n",
    "        if len(files) > 0:\n",
    "            for file in files:\n",
    "                if file.endswith('.txt'):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    outcome = read_file_and_return_outcomes(file_path)\n",
    "                    outcomes[outcome] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = [0 for _ in range(len(ERROR_CODE))]\n",
    "\n",
    "for root, subdirs, files in os.walk(ABSOLUTE_DIR):\n",
    "    if len(files) > 0:\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                outcome = read_file_and_return_outcomes(file_path)\n",
    "                outcomes[outcome] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOAL: 0\n",
      "COLLISION: 60\n",
      "LARGE_VEL: 0\n",
      "PATH_OFFSET: 0\n",
      "EGO_KILLED: 240\n",
      "EPS_LIMIT: 207\n",
      "PROCESS_KILL: 60\n",
      "BELIEF_NORM_0: 6\n",
      "INTENTION_ID: 1\n",
      "EGO_LESS_THAN_AGENT: 4\n",
      "STOP_SUDDENLY: 1\n"
     ]
    }
   ],
   "source": [
    "# print outcomes which is number of files for each category:\n",
    "# Convert ERROR_CODE to dict with key is number \n",
    "ERROR_CODE = {v: k for k, v in ERROR_CODE.items()}\n",
    "for i in range(len(outcomes)):\n",
    "    print(f\"{ERROR_CODE[i]}: {outcomes[i]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, I do simple statistics of tree:\n",
    "1/ Depth\n",
    "2/ Number of expanded nodes\n",
    "3/ Total nodes\n",
    "\n",
    "4/ Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_and_return_performances(file_name):\n",
    "    depths = []\n",
    "    trials = []\n",
    "    expanded_nodes = []\n",
    "    total_nodes = []\n",
    "    rewards = []\n",
    "\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if \"# nodes: expanded\" in line:\n",
    "                expanded, total, policy = line.split(\"=\")[-1].split(\"/\")\n",
    "                expanded_nodes.append(int(expanded))\n",
    "                total_nodes.append(int(total))\n",
    "            if \"Trials: no.\" in line:\n",
    "                depth = int(line.split(\"=\")[1].split(\"/\")[-1])\n",
    "                trial = int(line.split(\"=\")[1].split(\"/\")[0])\n",
    "                depths.append(depth)\n",
    "                trials.append(trial)\n",
    "\n",
    "            if \"reward **=\" in line:\n",
    "                rewards.append(float(line.split(\"=\")[-1]))\n",
    "\n",
    "    return depths, trials, expanded_nodes, total_nodes, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_depths: 7.521030030139836\n",
      "mean_trials: 464.6465879213932\n",
      "mean_expanded_nodes: 759.6961692787397\n",
      "mean_total_nodes: 2138.4852491520533\n",
      "mean_rewards: -2.235645391309308\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ABSOLUTE_DIR = '/home/phong/driving_data/original_gamma/'\n",
    "mean_depths = []\n",
    "mean_trials = []\n",
    "mean_expanded_nodes = []\n",
    "mean_total_nodes = []\n",
    "mean_rewards = []\n",
    "for root, subdirs, files in os.walk(ABSOLUTE_DIR):\n",
    "    if len(files) > 0:\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                #print(f\"Reading file {root}/{file}\")\n",
    "                file_path = os.path.join(root, file)\n",
    "                depths, trials, expanded_nodes, total_nodes, rewards = read_file_and_return_performances(file_path)\n",
    "                if len(depths) == 0:\n",
    "                    continue\n",
    "                mean_depths.append(np.mean(depths))\n",
    "                mean_trials.append(np.mean(trials))\n",
    "                mean_expanded_nodes.append(np.mean(expanded_nodes))\n",
    "                mean_total_nodes.append(np.mean(total_nodes))\n",
    "                mean_rewards.append(np.mean(rewards))\n",
    "\n",
    "                # print(f\"depths: {np.mean(depths)}\")\n",
    "                # print(f\"trials: {np.mean(trials)}\")\n",
    "                # print(f\"expanded_nodes: {np.mean(expanded_nodes)}\")\n",
    "                # print(f\"total_nodes: {np.mean(total_nodes)}\")\n",
    "                # print(f\"rewards: {np.mean(rewards)}\")\n",
    "            #break\n",
    "# print all the mean\n",
    "print(f\"mean_depths: {np.mean(mean_depths)}\")\n",
    "print(f\"mean_trials: {np.mean(mean_trials)}\")\n",
    "print(f\"mean_expanded_nodes: {np.mean(mean_expanded_nodes)}\")\n",
    "print(f\"mean_total_nodes: {np.mean(mean_total_nodes)}\")\n",
    "print(f\"mean_rewards: {np.mean(mean_rewards)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_depths: 6.092680190882702\n",
      "mean_trials: 20.356812577105764\n",
      "mean_expanded_nodes: 43.16904586682518\n",
      "mean_total_nodes: 111.25153285782861\n",
      "mean_rewards: -2.396472451905705\n"
     ]
    }
   ],
   "source": [
    "ABSOLUTE_DIR = '/home/phong/driving_data/gamma_1threads/'\n",
    "mean_depths = []\n",
    "mean_trials = []\n",
    "mean_expanded_nodes = []\n",
    "mean_total_nodes = []\n",
    "mean_rewards = []\n",
    "for root, subdirs, files in os.walk(ABSOLUTE_DIR):\n",
    "    if len(files) > 0:\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                #print(f\"Reading file {root}/{file}\")\n",
    "                file_path = os.path.join(root, file)\n",
    "                depths, trials, expanded_nodes, total_nodes, rewards = read_file_and_return_performances(file_path)\n",
    "                if len(depths) == 0:\n",
    "                    continue\n",
    "                mean_depths.append(np.mean(depths))\n",
    "                mean_trials.append(np.mean(trials))\n",
    "                mean_expanded_nodes.append(np.mean(expanded_nodes))\n",
    "                mean_total_nodes.append(np.mean(total_nodes))\n",
    "                mean_rewards.append(np.mean(rewards))\n",
    "\n",
    "                # print(f\"depths: {np.mean(depths)}\")\n",
    "                # print(f\"trials: {np.mean(trials)}\")\n",
    "                # print(f\"expanded_nodes: {np.mean(expanded_nodes)}\")\n",
    "                # print(f\"total_nodes: {np.mean(total_nodes)}\")\n",
    "                # print(f\"rewards: {np.mean(rewards)}\")\n",
    "            #break\n",
    "# print all the mean\n",
    "print(f\"mean_depths: {np.mean(mean_depths)}\")\n",
    "print(f\"mean_trials: {np.mean(mean_trials)}\")\n",
    "print(f\"mean_expanded_nodes: {np.mean(mean_expanded_nodes)}\")\n",
    "print(f\"mean_total_nodes: {np.mean(mean_total_nodes)}\")\n",
    "print(f\"mean_rewards: {np.mean(mean_rewards)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_depths: 4.8582280972087775\n",
      "mean_trials: 10.815689355182316\n",
      "mean_expanded_nodes: 21.265743568103478\n",
      "mean_total_nodes: 49.42439164767002\n",
      "mean_rewards: -2.2629980048776317\n"
     ]
    }
   ],
   "source": [
    "ABSOLUTE_DIR = '/home/phong/driving_data/lanegcn0_1_test14/'\n",
    "mean_depths = []\n",
    "mean_trials = []\n",
    "mean_expanded_nodes = []\n",
    "mean_total_nodes = []\n",
    "mean_rewards = []\n",
    "for root, subdirs, files in os.walk(ABSOLUTE_DIR):\n",
    "    if len(files) > 0:\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                #print(f\"Reading file {root}/{file}\")\n",
    "                file_path = os.path.join(root, file)\n",
    "                depths, trials, expanded_nodes, total_nodes, rewards = read_file_and_return_performances(file_path)\n",
    "                if len(depths) == 0:\n",
    "                    continue\n",
    "                mean_depths.append(np.mean(depths))\n",
    "                mean_trials.append(np.mean(trials))\n",
    "                mean_expanded_nodes.append(np.mean(expanded_nodes))\n",
    "                mean_total_nodes.append(np.mean(total_nodes))\n",
    "                mean_rewards.append(np.mean(rewards))\n",
    "\n",
    "                # print(f\"depths: {np.mean(depths)}\")\n",
    "                # print(f\"trials: {np.mean(trials)}\")\n",
    "                # print(f\"expanded_nodes: {np.mean(expanded_nodes)}\")\n",
    "                # print(f\"total_nodes: {np.mean(total_nodes)}\")\n",
    "                # print(f\"rewards: {np.mean(rewards)}\")\n",
    "            #break\n",
    "# print all the mean\n",
    "print(f\"mean_depths: {np.mean(mean_depths)}\")\n",
    "print(f\"mean_trials: {np.mean(mean_trials)}\")\n",
    "print(f\"mean_expanded_nodes: {np.mean(mean_expanded_nodes)}\")\n",
    "print(f\"mean_total_nodes: {np.mean(mean_total_nodes)}\")\n",
    "print(f\"mean_rewards: {np.mean(mean_rewards)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_depths: 0.12117889972108209\n",
      "mean_trials: 1.4337029211386783\n",
      "mean_expanded_nodes: 1.6702443862608376\n",
      "mean_total_nodes: 14.120152768435966\n",
      "mean_rewards: -2.7486576331937456\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ABSOLUTE_DIR = '/home/phong/driving_data/same_Hz/hivt3hz_fixed'\n",
    "mean_depths = []\n",
    "mean_trials = []\n",
    "mean_expanded_nodes = []\n",
    "mean_total_nodes = []\n",
    "mean_rewards = []\n",
    "for root, subdirs, files in os.walk(ABSOLUTE_DIR):\n",
    "    if len(files) > 0:\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                #print(f\"Reading file {root}/{file}\")\n",
    "                file_path = os.path.join(root, file)\n",
    "                depths, trials, expanded_nodes, total_nodes, rewards = read_file_and_return_performances(file_path)\n",
    "                if len(depths) == 0:\n",
    "                    continue\n",
    "                mean_depths.append(np.mean(depths))\n",
    "                mean_trials.append(np.mean(trials))\n",
    "                mean_expanded_nodes.append(np.mean(expanded_nodes))\n",
    "                mean_total_nodes.append(np.mean(total_nodes))\n",
    "                mean_rewards.append(np.mean(rewards))\n",
    "\n",
    "                # print(f\"depths: {np.mean(depths)}\")\n",
    "                # print(f\"trials: {np.mean(trials)}\")\n",
    "                # print(f\"expanded_nodes: {np.mean(expanded_nodes)}\")\n",
    "                # print(f\"total_nodes: {np.mean(total_nodes)}\")\n",
    "                # print(f\"rewards: {np.mean(rewards)}\")\n",
    "            #break\n",
    "# print all the mean\n",
    "print(f\"mean_depths: {np.mean(mean_depths)}\")\n",
    "print(f\"mean_trials: {np.mean(mean_trials)}\")\n",
    "print(f\"mean_expanded_nodes: {np.mean(mean_expanded_nodes)}\")\n",
    "print(f\"mean_total_nodes: {np.mean(mean_total_nodes)}\")\n",
    "print(f\"mean_rewards: {np.mean(mean_rewards)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e4da2c496607fa87da4e17f6dba7bea7d0478acd423d0a117f2ff92428ad5bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
